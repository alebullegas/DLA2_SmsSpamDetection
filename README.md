# ğŸ›¡ï¸ DLA2: SMS SPAM DETECTION 2024/25 - UNICA

<p align="center">
  <a href="https://www.apache.org/licenses/LICENSE-2.0" target="_blank">
    <img src="https://img.shields.io/badge/License-Apache_2.0-4285F4?style=for-the-badge&logo=none&logoColor=white" alt="Apache License 2.0"/>
  </a>
  <a href="https://lmstudio.ai/" target="_blank">
    <img src="https://img.shields.io/badge/Inference-LM_Studio-5A29E4?style=for-the-badge&logo=openai&logoColor=white" alt="LM Studio"/>
  </a>
  <a href="https://unsloth.ai/" target="_blank">
    <img src="https://img.shields.io/badge/Training-Unsloth_AI-000000?style=for-the-badge&logo=huggingface&logoColor=white" alt="Unsloth"/>
  </a>
  <a href="https://python.langchain.com/" target="_blank">
    <img src="https://img.shields.io/badge/Orchestration-LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white" alt="LangChain"/>
  </a>
</p>

<p align="center">
  Progetto di <b>Binary Classification</b> su SMS Spam confrontando diversi modelli.
</p>

---

> ## ğŸ“‘ Indice
> 01. [ğŸ§‘ğŸ»â€ğŸ“ Studente](#studente)  
> 02. [ğŸ“Œ Descrizione](#descrizione)  
> 03. [ğŸ“„ Panoramica File](#panoramica-file)  
> 04. [ğŸ“ Struttura del Progetto](#struttura-progetto)  
> 05. [ğŸ› ï¸ Stack Tecnologico](#stack-tecnologico)  
> 06. [ğŸš€ Installazione](#installazione)  
> 07. [ğŸ§ª Run: Processo di Fine-Tuning](#fine-tuning)  
> 08. [ğŸ“Š Run: Benchmark e Confronto](#benchmark)  
> 09. [ğŸ“ˆ Metriche e Risultati](#metriche)  
> 10. [ğŸ–¥ï¸ Hardware e Limitazioni](#hardware)  
> 11. [ğŸ“ Licenze](#licenze)  
> 12. [â“ Come Citare](#citare)

---

## 1. ğŸ§‘ğŸ»â€ğŸ“ Studente <a name="studente"></a>
> **Alessandro Bullegas**
> - **Matricola:** 60/73/65307
> - **Email:** alebullegas31@gmail.com
>
> - ---


## 2. ğŸ“Œ Descrizione <a name="descrizione"></a>

Questo progetto nasce come studio sperimentale per analizzare i trade-off tra **dimensione del modello**, **capacitÃ  di ragionamento** (Reasoning) e **specializzazione del dominio** nel contesto della Spam Detection.

I Large Language Models (LLM) classici sono strumenti molto potenti ma, spesso, peccano di velocitÃ  e stretta aderenza alle richieste dei task che vengono affidati, come ad esempio filtrare SMS malevoli.

Utilizzando il dataset pubblico **SMS Spam Collection**, il progetto mette a confronto tre filosofie diverse:

1.  **Zero-Shot Generalist:** `Llama 3.2 3B Instruct`. Un modello leggero e generico, testato sulla sua capacitÃ  di riconoscere lo spam senza addestramento specifico.
2.  **Chain-of-Thought Reasoning:** `DeepSeek R1`. Un modello progettato per "pensare" prima di rispondere. Testiamo se il ragionamento logico aiuta a scovare tentativi di phishing piÃ¹ sottili o se aggiunge solo latenza inutile.
3.  **Domain Specialist:** `Llama 3.2 3B Fine-Tuned`. La versione custom, addestrata specificamente.

### ğŸ¯ Obiettivo
Dimostrare che un **modello piccolo ma specializzato (Fine-Tuned)** puÃ² superare modelli piÃ¹ complessi o "ragionanti" in task verticali, offrendo:
* âœ… **Latenza Minore**
* âœ… **Accuratezza Superiore**


## 3. ğŸ“„ Panoramica File <a name="panoramica-file"></a>

| File | Tipo | Descrizione |
| :--- | :--- | :--- |
| `split_dataset.py` | ğŸ Script | Lo script che si occupa di pulire il dataset raw (`spam.csv`), mescolarlo e dividerlo rigorosamente in Training Set (80%) e Test Set (20%) per evitare *Overfitting*. |
| `model_evaluation.py` | ğŸ Script | Lo script che interroga LM Studio, misura la latenza e calcola le metriche (Accuracy, Precision, Recall) sui modelli. |
| `train_unsloth.jsonl` | ğŸ“„ Dati | Il file JSONL formattato contenente solo gli esempi per l'addestramento da utilizzare su Colab. |
| `test_benchmark.csv` | ğŸ“„ Dati | Il dataset "invisibile" usato solo per la valutazione finale. |
| `Finetuning_Spam.ipynb` | ğŸ““ Notebook | Il notebook Colab che esegue l'addestramento QLoRA e l'esportazione GGUF. |


## 4. ğŸ“ Struttura del Progetto <a name="struttura-progetto"></a>

```plaintext
â”œâ”€â”€ ğŸ“ data/                      # Contiene i dataset (Raw, Train, Test)
â”‚   â”œâ”€â”€ spam.csv                  # Dataset originale
â”‚   â”œâ”€â”€ train_unsloth.jsonl       # Dataset formattato per il training
â”‚   â””â”€â”€ test_benchmark.csv        # Dataset riservato per il test
â”‚
â”œâ”€â”€ ğŸ“ models/                    # Cartella per i modelli GGUF
â”‚   â””â”€â”€ Llama-3.2-3B-Instruct.Q4_K_M.gguf # Il modello Fine-Tunato
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                  # Codice per il fine tuning
â”‚   â””â”€â”€ Finetuning_Spam.ipynb      # Notebook Google Colab
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Codice sorgente Python
â”‚   â”œâ”€â”€ model_evaluation.py       # Script di validazione
â”‚   â””â”€â”€ split_dataset.py          # Script di preparazione dati
â”‚
â”œâ”€â”€ ğŸ“ results/                   # Output dei test
â”‚   â””â”€â”€ risultati_benchmark.csv   # Risultati grezzi per ogni SMS
â”‚
â””â”€â”€ README.md                     # Documentazione
```

## 5. ğŸ› ï¸ Stack Tecnologico <a name="stack-tecnologico"></a>
### ğŸŸ£ LM Studio
**LM Studio** non viene usato come semplice interfaccia grafica, ma come vero e proprio **Server Locale**.
* **Ruolo Architetturale:** LM Studio carica i modelli e sfrutta la GPU/CPU del pc per eseguire i calcoli.
* **Integrazione API:** La funzionalitÃ  chiave utile per il progetto Ã¨ il suo **Local Server** compatibile con le specifiche OpenAI (`http://localhost:1234/v1`). Questo ci permette di disaccoppiare il modello dallo script Python: possiamo sostituire il "motore" (es. passando da un modello ad un altro) in tempo reale senza modificare il codice.

### ğŸ¦œğŸ”— LangChain
**LangChain** funge come livello di astrazione logica tra il nostro codice Python e il modello linguistico.
* **Prompt Templating:** Gestisce la costruzione dinamica dei messaggi, inserendo il `System Prompt` (le regole di sicurezza) e lo `User Prompt` (l'SMS da analizzare) nel formato corretto atteso dal modello.
* **Output Parsing:** Utilizzando `StrOutputParser`, LangChain intercetta la risposta grezza dell'LLM e la pulisce da eventuali meta-tag o spazi bianchi, garantendo che il dato salvato nel CSV sia pulito e pronto per l'analisi.

### ğŸ¦¥ Unsloth AI (Optimization Library)
Per la fase di Fine-Tuning su Google Colab, viene utilizzata la libreria **Unsloth**, che rappresenta uno strumento fondamentale per migliorare l'efficienza nell'addestramento degli LLM.
* **PerchÃ© Ã¨ essenziale:** Il Fine-Tuning tradizionale di Llama 3 richiederebbe GPU potentissime (A100, 40GB VRAM).
* **Innovazione Tecnica:** Unsloth implementa kernel PyTorch riscritti per l'ottimizzazione e utilizza la tecnica **QLoRA** (Quantized Low-Rank Adaptation).
* **Risultato:** Questo stack ci ha permesso di addestrare un modello da 3 miliardi di parametri su una GPU Tesla T4 gratuita (16GB VRAM), riducendo i tempi di training di 2x e l'occupazione di memoria del 60%.




